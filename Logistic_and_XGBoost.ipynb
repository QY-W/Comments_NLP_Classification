{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "93c6cbef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.12 (main, Apr  4 2022, 05:22:27) [MSC v.1916 64 bit (AMD64)]\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695b081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical, pad_sequences\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d4cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wei99\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\wei99\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\wei99\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\wei99\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# python version 3.8.6rc1\n",
    "import pandas as pd\n",
    "import string\n",
    "import util\n",
    "import io\n",
    "import os\n",
    "from pprint import pprint\n",
    "import spacy\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='once')\n",
    "#warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "# import pyLDAvis\n",
    "# import pyLDAvis.gensim_models\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "# %matplotlib inline\n",
    "# import pandas as pd\n",
    "# from sklearn.feature_extraction.text import CountVectorizer\n",
    "# from sklearn import metrics\n",
    "# from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66360c92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    143346\n",
      "1     16225\n",
      "Name: harmful, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wei99\\AppData\\Local\\Temp\\ipykernel_36132\\716027470.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  comments['harmful'][comments['harmful']>0] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>harmful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\r\\nWhy the edits made under my use...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\r\\nMore\\r\\nI can't make any real suggestions...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  harmful\n",
       "0  Explanation\\r\\nWhy the edits made under my use...        0\n",
       "1  D'aww! He matches this background colour I'm s...        0\n",
       "2  Hey man, I'm really not trying to edit war. It...        0\n",
       "3  \"\\r\\nMore\\r\\nI can't make any real suggestions...        0\n",
       "4  You, sir, are my hero. Any chance you remember...        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count number of rows with each label without considering combination\n",
    "comments = pd.read_csv(\"train.csv\")\n",
    "#comments.iloc[:, 2:].sum(axis=0)\n",
    "\n",
    "df_multilabel = comments\n",
    "\n",
    "# convert into binary\n",
    "comments['harmful'] = comments.iloc[:, 2:].sum(axis=1)\n",
    "comments['harmful'][comments['harmful']>0] = 1\n",
    "\n",
    "# keep necessary info\n",
    "df = comments[['comment_text',\"harmful\"]]#.copy()\n",
    "\n",
    "print(df['harmful'].value_counts())\n",
    "df.head()\n",
    "\n",
    "sns.countplot(df['harmful'])\n",
    "plt.xlabel('Label')\n",
    "plt.title('Number of harmful messages')\n",
    "\n",
    "df_harmful = df[df['harmful'] > 0] \n",
    "df_not_harmful = df[df['harmful'] == 0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3cd91d",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee367bde",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Randomly select 15% of not harmful instances + all harmful instances\n",
    "df_not_harmful_sample = df_not_harmful.sample(frac=0.15)\n",
    "sample_df = pd.concat([df_not_harmful_sample, df_harmful], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d956cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    text = text.lower()\n",
    "    regex = re.compile('[' + re.escape(string.punctuation) + '0-9\\\\r\\\\t\\\\n]')\n",
    "    nopunct = regex.sub(\" \", text)\n",
    "    words = nopunct.split(' ')\n",
    "    # remove any non ascii\n",
    "    words = [word.encode('ascii', 'ignore').decode('ascii') for word in words]\n",
    "    lmtzr = WordNetLemmatizer()\n",
    "    words = [lmtzr.lemmatize(w) for w in words]\n",
    "    words = [w for w in words if len(w) > 2]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5e2799f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train = sample_df.sample(frac=0.80)\n",
    "test = sample_df.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df308f4c",
   "metadata": {},
   "source": [
    "## Applying TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18f5c894",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(ngram_range=(1, 1), analyzer='word',\n",
    "                         tokenizer=tokenize, stop_words='english',\n",
    "                         strip_accents='unicode', use_idf=1, min_df=10)\n",
    "X_train = vector.fit_transform(train['comment_text'])\n",
    "X_test = vector.transform(test['comment_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c15da518",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['harmful']\n",
    "Y_test = test['harmful']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d5c2c9",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5636f207",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression_classifier = LogisticRegression()\n",
    "\n",
    "logistic_regression_classifier.fit(X_train, train['harmful'])\n",
    "predicted = logistic_regression_classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e815d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression: 0.8971504307488403\n",
      "Recall of logistic regression: 0.8295800365185636\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "print(\"Accuracy of logistic regression:\",accuracy_score(test['harmful'], predicted))\n",
    "print(\"Recall of logistic regression:\",recall_score(test['harmful'], predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7acbb9",
   "metadata": {},
   "source": [
    "## Logistic regression Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8339c906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'class_weight': 'balanced', 'solver': 'liblinear'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(class_weight='balanced', solver='liblinear')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {'solver': ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "                  'class_weight': [None, 'balanced']}\n",
    "\n",
    "cross_validation = StratifiedKFold(n_splits=5)\n",
    "\n",
    "grid_search = GridSearchCV(logistic_regression_classifier,\n",
    "                           param_grid=parameter_grid,\n",
    "                           cv=cross_validation,\n",
    "                           scoring='f1')\n",
    "\n",
    "grid_search.fit(X_train, train['harmful'])\n",
    "\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a82e287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of logistic regression after Hyperparameter Tuning with Grid Search: 0.9015241882041087\n",
      "Recall of logistic regression after Hyperparameter Tuning with Grid Search: 0.8627510651247717\n"
     ]
    }
   ],
   "source": [
    "lr_gs = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "lr_gs.fit(X_train, train['harmful'])\n",
    "lrgs_predicted = lr_gs.predict(X_test)\n",
    "print(\"Accuracy of logistic regression after Hyperparameter Tuning with Grid Search:\",accuracy_score(test['harmful'], lrgs_predicted))\n",
    "print(\"Recall of logistic regression after Hyperparameter Tuning with Grid Search:\",recall_score(test['harmful'], lrgs_predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d659fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wei99\\AppData\\Local\\Temp\\ipykernel_36132\\935626199.py:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(y_true=Y_test, y_pred=lrgs_predicted)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "plt.savefig(\"logistic.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81bb1e34",
   "metadata": {},
   "source": [
    "# Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ba190b8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of XGBoost: 0.8779324055666003\n",
      "Recall of XGBoost: 0.759281801582471\n"
     ]
    }
   ],
   "source": [
    "xgb = xgb.XGBClassifier(objective='binary:logistic',eval_metric='error')\n",
    "\n",
    "xgb.fit(X_train, train['harmful'])\n",
    "xgb_prediction = xgb.predict(X_test)\n",
    "print(\"Accuracy of XGBoost:\",accuracy_score(test['harmful'], xgb_prediction))\n",
    "print(\"Recall of XGBoost:\",recall_score(test['harmful'], xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9aa0e52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wei99\\AppData\\Local\\Temp\\ipykernel_36132\\1112707220.py:14: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "conf_matrix_XGB = confusion_matrix(y_true=Y_test, y_pred=xgb_prediction)\n",
    "#\n",
    "# Print the confusion matrix using Matplotlib\n",
    "#\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix_XGB, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix_XGB.shape[0]):\n",
    "    for j in range(conf_matrix_XGB.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix_XGB[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()\n",
    "plt.savefig(\"XGBoost_CM.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "916e650a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
